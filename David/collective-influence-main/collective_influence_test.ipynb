{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Feb 26 11:57:55 2020\n",
    "\n",
    "@author: RavindranathNemani\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(100**3)\n",
    "\n",
    "sys.path.append('./')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import heaps\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#sp = find_shortest_path(graph, vertex, node)\n",
    "def find_shortest_path(graph, start, end, path=[]):\n",
    "        #print(\"start in find_shortest_path---\" , start)\n",
    "        #print(\"end in find_shortest_path---\" , end)\n",
    "\n",
    "        path = path + [start]\n",
    "\n",
    "        if start == end:\n",
    "            #print(\"The path is..............................\", path)\n",
    "            return path\n",
    "\n",
    "        if not start in graph.keys():\n",
    "            return None\n",
    "\n",
    "        shortest = None\n",
    "\n",
    "        for node in graph[start]:\n",
    "\n",
    "            if node not in path:\n",
    "                #print(\"node in find_shortest_path---\" , node)\n",
    "                #print(\"graph[start] in find_shortest_path---\", graph[start])\n",
    "                newpath = find_shortest_path(graph, node, end, path)\n",
    "                #print(newpath)\n",
    "\n",
    "                if newpath:\n",
    "                    if not shortest or len(newpath) < len(shortest):\n",
    "                        shortest = newpath\n",
    "        #print(shortest)\n",
    "        #input(\"___\")\n",
    "        return shortest\n",
    "\n",
    "\n",
    "def find_nodes_on_frontier(graph, vertex, st, l):\n",
    "\n",
    "    if l == 0:\n",
    "        st.add(vertex)\n",
    "\n",
    "    else:\n",
    "        st.add(vertex)\n",
    "\n",
    "        #print(graph[vertex])\n",
    "        #input(\"hello\")\n",
    "        for n in graph[vertex]:\n",
    "            find_nodes_on_frontier(graph, n, st, l-1)\n",
    "\n",
    "    return st\n",
    "\n",
    "\n",
    "def get_keys_list(ci):\n",
    "\n",
    "    l = []\n",
    "\n",
    "    for key in ci.keys():\n",
    "        l.append(key)\n",
    "\n",
    "    return(l)\n",
    "\n",
    "\n",
    "def find_nodes_on_frontier1(graph, ngraph, vertex, l):\n",
    "\n",
    "    all_nodes = list(find_nodes_on_frontier(graph, vertex, set(), l))\n",
    "    #print(all_nodes)\n",
    "    #input(\"all_nodes\")\n",
    "    #input(\"in the ball\")\n",
    "\n",
    "    sp_dists = {}\n",
    "    for node in all_nodes:\n",
    "        #input(\"in the ball___\")\n",
    "        #print(\"node in fun(find_nodes_on_frontier1)----\" , node)\n",
    "        sp = nx.shortest_path(ngraph, vertex, node)\n",
    "        #print(sp)\n",
    "        #input(\"shortest path is............................\")\n",
    "        #sp = find_shortest_path(graph, vertex, node)\n",
    "        #sp.remove(vertex)\n",
    "        #print(\"node\")\n",
    "        #print(node)\n",
    "        #print(\"sp\")\n",
    "        #print(len(sp))\n",
    "        #input(\"uday\")\n",
    "        sp_dists[node] = len(sp)\n",
    "\n",
    "    for key in sp_dists.copy():\n",
    "        if sp_dists[key] < l+1:\n",
    "            del sp_dists[key]\n",
    "\n",
    "    return get_keys_list(sp_dists)\n",
    "\n",
    "\n",
    "def mean(d):\n",
    "\n",
    "    mean = 0.0\n",
    "\n",
    "    for key in d.keys():\n",
    "        mean = mean + d[key]\n",
    "\n",
    "    mean = mean / len(d)\n",
    "\n",
    "    return(mean)\n",
    "\n",
    "\n",
    "def get_degrees(graph):\n",
    "\n",
    "    degrees = graph.copy()\n",
    "\n",
    "    for key in graph.keys():\n",
    "        degrees[key] = len(graph[key])\n",
    "\n",
    "    return degrees\n",
    "\n",
    "\n",
    "def get_reduced_degrees(graph):\n",
    "\n",
    "    degrees = graph.copy()\n",
    "\n",
    "    for key in graph.keys():\n",
    "        degrees[key] = len(graph[key]) - 1\n",
    "\n",
    "    return degrees\n",
    "\n",
    "\n",
    "def collective_influence(graph, ngraph, l):\n",
    "\n",
    "    degs = get_reduced_degrees(graph)\n",
    "    #print(degs)\n",
    "    #input(\"test0\")\n",
    "\n",
    "    ci = graph.copy()\n",
    "    #print(graph)\n",
    "    #input(\"rtest\")\n",
    "    #i = 0\n",
    "    for vertex in graph.keys():\n",
    "        #print(vertex)\n",
    "        #input(\"vertex\")\n",
    "        neighborhood = find_nodes_on_frontier1(graph, ngraph, vertex, l)\n",
    "        #print(neighborhood)\n",
    "        neighborhood = list(neighborhood)\n",
    "        if vertex in neighborhood:\n",
    "            neighborhood.remove(vertex)\n",
    "        #print(neighborhood)\n",
    "        #input(\"neighborhood\")\n",
    "\n",
    "        ci_vertex = degs[vertex]\n",
    "        su = 0.0\n",
    "\n",
    "        for node in range(len(neighborhood)):\n",
    "            #print(node)\n",
    "            #print(neighborhood[node])\n",
    "            #print(degs)\n",
    "            #print(degs[neighborhood[node]])\n",
    "            #input(\"test1\")\n",
    "            su = su + degs[neighborhood[node]]\n",
    "\n",
    "        ci_vertex = int(ci_vertex * su)\n",
    "        ci[vertex] = ci_vertex\n",
    "        #print(i)\n",
    "        #i = i+1\n",
    "    return(ci)\n",
    "\n",
    "\n",
    "def approximate_largest_eigenvalue(graph, l, ci):\n",
    "\n",
    "    #ci = collective_influence(graph)\n",
    "\n",
    "    k = get_degrees(graph)\n",
    "\n",
    "    lambd = mean(ci) / mean(k)\n",
    "    #print(l)\n",
    "    #input(\"exponent\")\n",
    "    exponent = 1 / (l+1)\n",
    "    lambd = pow(lambd, exponent)\n",
    "\n",
    "    return(lambd)\n",
    "\n",
    "\n",
    "def get_list(ci):\n",
    "\n",
    "    l = []\n",
    "\n",
    "    for key in ci.keys():\n",
    "        l.append(ci[key])\n",
    "\n",
    "    return(l)\n",
    "\n",
    "\n",
    "def delete_vertex(graph, vertex):\n",
    "\n",
    "    if vertex in graph.keys():\n",
    "        del graph[vertex]\n",
    "        #print(graph)\n",
    "\n",
    "    for key in graph.keys():\n",
    "        if vertex in graph[key]:\n",
    "            graph[key].remove(vertex)\n",
    "\n",
    "    return(graph)\n",
    "\n",
    "\n",
    "def get_vertex(ci, maximum_ci):\n",
    "    for key in ci.keys():\n",
    "        if ci[key] == maximum_ci:\n",
    "            break\n",
    "\n",
    "    return key\n",
    "\n",
    "\n",
    "def update_values(graph, l, ci):\n",
    "\n",
    "    #ci = collective_influence(graph, ngraph, l)\n",
    "\n",
    "    ev = approximate_largest_eigenvalue(graph, l, ci)\n",
    "\n",
    "    lst = get_list(ci)\n",
    "\n",
    "    max_heap = heaps.MaxHeap(lst)\n",
    "    #print(type(max_heap))\n",
    "    #input(\"test0\")\n",
    "\n",
    "    return max_heap, ev\n",
    "\n",
    "\n",
    "def collective_influence_only_in_ball(graph1, ngraph1, vertex, l, ci):\n",
    "\n",
    "    degs = get_reduced_degrees(graph1)\n",
    "    #print(vertex)\n",
    "    #input(\"ravi\")\n",
    "\n",
    "    neighborhood = set()\n",
    "\n",
    "    for j in range(l+2):\n",
    "        if j > 0:\n",
    "            neighborhood.update(find_nodes_on_frontier1(graph1, ngraph1, vertex, j))\n",
    "\n",
    "    delete_vertex(graph1, vertex)\n",
    "    ngraph1 = nx.from_dict_of_lists(graph1)\n",
    "\n",
    "    del ci[vertex]\n",
    "\n",
    "    for node in neighborhood:\n",
    "        node_neighborhood = find_nodes_on_frontier1(graph1, ngraph1, node, l)\n",
    "\n",
    "        node_neighborhood = list(node_neighborhood)\n",
    "        if node in node_neighborhood:\n",
    "            node_neighborhood.remove(node)\n",
    "\n",
    "        ci_node = degs[node]\n",
    "\n",
    "        su = 0.0\n",
    "\n",
    "        for n in range(len(node_neighborhood)):\n",
    "            #print(node)\n",
    "            #print(neighborhood[node])\n",
    "            #print(degs)\n",
    "            #print(degs[neighborhood[node]])\n",
    "            #input(\"test1\")\n",
    "            su = su + degs[node_neighborhood[n]]\n",
    "\n",
    "        ci_node = int(ci_node * su)\n",
    "        ci[node] = ci_node\n",
    "\n",
    "    return(ci)\n",
    "\n",
    "\n",
    "def get_influencers(graph, ngraph, l):\n",
    "\n",
    "    ci = collective_influence(graph, ngraph, l)\n",
    "    #print(ci)\n",
    "    #input(\"test\")\n",
    "    lst = get_list(ci)\n",
    "\n",
    "    max_heap = heaps.MaxHeap(lst)\n",
    "\n",
    "    #max_heap = heaps.MaxHeap.get_list(max_heap)\n",
    "\n",
    "    ev = approximate_largest_eigenvalue(graph, l, ci)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    removed_vertices = []\n",
    "\n",
    "    while ev > 1:\n",
    "\n",
    "        #create a copy\n",
    "        #graph1 = graph.copy()\n",
    "\n",
    "        #heapify\n",
    "        #max_heap = heaps.MaxHeap.get_list(max_heap)\n",
    "        lst1 = get_list(ci)\n",
    "\n",
    "        max_heap = heaps.MaxHeap(lst1)\n",
    "\n",
    "        #extract_max\n",
    "        maximum_ci = heaps.MaxHeap.extract_max(max_heap)\n",
    "        #print(maximum_ci)\n",
    "        #input(\"maximum\")\n",
    "        #print(maximum_ci)\n",
    "        #input(\"test1\")\n",
    "        #delete root in heap\n",
    "        #heaps.MaxHeap.delete()\n",
    "\n",
    "        #locate the vertex which has maximum_ci as it's maximum value\n",
    "        vertex = get_vertex(ci, maximum_ci)\n",
    "        #print(ci)\n",
    "        #input(\"ci\")\n",
    "        #print(vertex)\n",
    "        #input(\"test2\")\n",
    "\n",
    "        #create copies of original graph before deleting the vertex\n",
    "        graph1 = graph.copy()\n",
    "        ngraph1 = ngraph.copy()\n",
    "\n",
    "        #also delete corresponding node from the graph\n",
    "        delete_vertex(graph, vertex)\n",
    "        ngraph = nx.from_dict_of_lists(graph)\n",
    "\n",
    "        #heapify\n",
    "        max_heap = heaps.MaxHeap.get_list(max_heap)\n",
    "\n",
    "        #update CI values\n",
    "        #max_heap, ev = update_values(graph, l)\n",
    "\n",
    "        #heapify\n",
    "        #max_heap = heaps.MaxHeap.get_list(max_heap)\n",
    "\n",
    "        #compute new ci values\n",
    "        #ci = collective_influence(graph, ngraph, l)\n",
    "        #change CI values only within ball of radius l+1\n",
    "        ci = collective_influence_only_in_ball(graph1, ngraph1, vertex, l, ci)\n",
    "        max_heap, ev = update_values(graph, l, ci)\n",
    "        #compute new largest eigenvalue\n",
    "        ev = approximate_largest_eigenvalue(graph, l, ci)\n",
    "\n",
    "        removed_vertices.append(vertex)\n",
    "\n",
    "        #print(ev)\n",
    "        #print(i)\n",
    "        #input(\"test3\")\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "    return(removed_vertices)\n",
    "'''\n",
    "graph = { 1 : [2, 3],\n",
    "      2 : [1, 4, 5, 6],\n",
    "      3 : [1, 4],\n",
    "      4 : [2, 3, 5],\n",
    "      5 : [2, 4, 6],\n",
    "      6 : [2, 5]\n",
    "    }\n",
    "\n",
    "ci = collective_influence(graph, 1)\n",
    "\n",
    "l = get_list(ci)\n",
    "\n",
    "max_heap = heaps.MaxHeap(l)\n",
    "l1 = heaps.MaxHeap.get_list(max_heap)\n",
    "print(\"Hello\")\n",
    "print(type(l1))\n",
    "print(l1)\n",
    "'''\n",
    "\n",
    "def get_graph():\n",
    "\n",
    "    edges = [1,4, 2,4, 3,4, 3,5, 4,5, 4,7, 5,6, 5,29, 6,7, 6,10, 6,20, 7,8, 7,9, 7,10, 10,11, 10,30, 11,12, 11,17, 12,13, 12,14, 12,15, 12,16, 14,15, 16,17, 17,18, 17,29, 18,19, 18,20, 20,21, 21,22, 21,23, 21,24, 21,27, 21,30, 22,23, 24,25, 24,26, 24,27, 24,29, 26,27, 27,28, 27,29]\n",
    "\n",
    "    num_edges = int(len(edges)/2)\n",
    "\n",
    "    vertices = list(np.unique(edges))\n",
    "\n",
    "    #add vertices\n",
    "\n",
    "    graph = {}\n",
    "\n",
    "    for i in range(len(vertices)):\n",
    "\n",
    "        graph[vertices[i]] = []\n",
    "\n",
    "    for j in range(len(vertices)):\n",
    "\n",
    "        for k in range(num_edges):\n",
    "\n",
    "            if vertices[j] == edges[2*k+1]:\n",
    "                graph[vertices[j]].append(edges[2*k])\n",
    "\n",
    "            elif vertices[j] == edges[2*k]:\n",
    "                graph[vertices[j]].append(edges[2*k+1])\n",
    "\n",
    "    return(graph)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    df = pd.read_csv('C:/Users/RavindranathNemani/Desktop/DeepLearning/R/Sanjeev/Relation/data.txt', sep = \"\\t\", header = None, names = [\"vertex\", \"edges\"])\n",
    "\n",
    "    graph = {}\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        edge_string = df.loc[i, \"edges\"]\n",
    "        edge_list = edge_string.split(',')\n",
    "\n",
    "        graph[df.loc[i, \"vertex\"]] = edge_list\n",
    "\n",
    "        #print(edge_string)\n",
    "        #input(\"edge_string\")\n",
    "    return(graph)\n",
    "\n",
    "\n",
    "def graph_check(graph):\n",
    "    #i = 0\n",
    "    vertex_list_from_edges = []\n",
    "    for vertex in graph.keys():\n",
    "        #print(vertex)\n",
    "        #print(i)\n",
    "        #i = i+1\n",
    "        vertex_list_from_edges = vertex_list_from_edges + graph[vertex]\n",
    "\n",
    "    vertex_list_from_edges = np.unique(vertex_list_from_edges)\n",
    "    #vertex_list_from_edges.sort()\n",
    "    vertex_list_from_edges = list(vertex_list_from_edges)\n",
    "    vertex_list_from_edges = set(vertex_list_from_edges)\n",
    "\n",
    "    vertex_list = get_keys_list(graph)\n",
    "    #vertex_list.sort()\n",
    "    vertex_list = set(vertex_list)\n",
    "\n",
    "    #print(type(vertex_list))\n",
    "    #input(\"original\")\n",
    "    #print(type(vertex_list_from_edges))\n",
    "    #input(\"from edges\")\n",
    "\n",
    "    if vertex_list == vertex_list_from_edges:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 26\u001b[0m\n\u001b[1;32m     16\u001b[0m graph \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mto_dict_of_lists(ngraph)\n\u001b[1;32m     17\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mif graph_check(graph):\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m    print(\"Graph is properly structured\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m    #input(\"npot correct\")\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m removed_vertices \u001b[39m=\u001b[39m get_influencers(graph, ngraph, \u001b[39m3\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(removed_vertices)\n",
      "Cell \u001b[0;32mIn [1], line 286\u001b[0m, in \u001b[0;36mget_influencers\u001b[0;34m(graph, ngraph, l)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_influencers\u001b[39m(graph, ngraph, l):\n\u001b[0;32m--> 286\u001b[0m     ci \u001b[39m=\u001b[39m collective_influence(graph, ngraph, l)\n\u001b[1;32m    287\u001b[0m     \u001b[39m#print(ci)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[39m#input(\"test\")\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     lst \u001b[39m=\u001b[39m get_list(ci)\n",
      "Cell \u001b[0;32mIn [1], line 155\u001b[0m, in \u001b[0;36mcollective_influence\u001b[0;34m(graph, ngraph, l)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m#print(graph)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m#input(\"rtest\")\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m#i = 0\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39mfor\u001b[39;00m vertex \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    153\u001b[0m     \u001b[39m#print(vertex)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[39m#input(\"vertex\")\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     neighborhood \u001b[39m=\u001b[39m find_nodes_on_frontier1(graph, ngraph, vertex, l)\n\u001b[1;32m    156\u001b[0m     \u001b[39m#print(neighborhood)\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     neighborhood \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(neighborhood)\n",
      "Cell \u001b[0;32mIn [1], line 91\u001b[0m, in \u001b[0;36mfind_nodes_on_frontier1\u001b[0;34m(graph, ngraph, vertex, l)\u001b[0m\n\u001b[1;32m     87\u001b[0m sp_dists \u001b[39m=\u001b[39m {}\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m all_nodes:\n\u001b[1;32m     89\u001b[0m     \u001b[39m#input(\"in the ball___\")\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39m#print(\"node in fun(find_nodes_on_frontier1)----\" , node)\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     sp \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mshortest_path(ngraph, vertex, node)\n\u001b[1;32m     92\u001b[0m     \u001b[39m#print(sp)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39m#input(\"shortest path is............................\")\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m#sp = find_shortest_path(graph, vertex, node)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39m#print(len(sp))\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m#input(\"uday\")\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     sp_dists[node] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(sp)\n",
      "File \u001b[0;32m~/miniforge3/envs/NS/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/generic.py:165\u001b[0m, in \u001b[0;36mshortest_path\u001b[0;34m(G, source, target, weight, method)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[39m# Find shortest source-target path.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39munweighted\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 165\u001b[0m         paths \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mbidirectional_shortest_path(G, source, target)\n\u001b[1;32m    166\u001b[0m     \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdijkstra\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    167\u001b[0m         _, paths \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mbidirectional_dijkstra(G, source, target, weight)\n",
      "File \u001b[0;32m~/miniforge3/envs/NS/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/unweighted.py:224\u001b[0m, in \u001b[0;36mbidirectional_shortest_path\u001b[0;34m(G, source, target)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNodeNotFound(msg)\n\u001b[1;32m    223\u001b[0m \u001b[39m# call helper to do the real work\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m results \u001b[39m=\u001b[39m _bidirectional_pred_succ(G, source, target)\n\u001b[1;32m    225\u001b[0m pred, succ, w \u001b[39m=\u001b[39m results\n\u001b[1;32m    227\u001b[0m \u001b[39m# build path from pred+w+succ\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/NS/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/unweighted.py:279\u001b[0m, in \u001b[0;36m_bidirectional_pred_succ\u001b[0;34m(G, source, target)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 forward_fringe\u001b[39m.\u001b[39mappend(w)\n\u001b[1;32m    278\u001b[0m                 pred[w] \u001b[39m=\u001b[39m v\n\u001b[0;32m--> 279\u001b[0m             \u001b[39mif\u001b[39;00m w \u001b[39min\u001b[39;00m succ:  \u001b[39m# path found\u001b[39;00m\n\u001b[1;32m    280\u001b[0m                 \u001b[39mreturn\u001b[39;00m pred, succ, w\n\u001b[1;32m    281\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "sp = find_shortest_path(graph, 3, 21)\n",
    "print(sp)\n",
    "input(\"sp\")\n",
    "\n",
    "ngbhd = find_nodes_on_frontier1(graph, 3, 3)\n",
    "print(ngbhd)\n",
    "input(\"ravi\")\n",
    "'''\n",
    "ngraph = nx.read_gml('/Users/davidguzman/Documents/GitHub/Network-Science-final-Maximization-/Proud_Boys_Datsets/PB2020.gml')\n",
    "ngraph = ngraph.reverse()\n",
    "# make simmetric\n",
    "ngraph = ngraph.to_undirected() # using an undirected adjacency matrix means its eigenvalues can be complex, which conflicts with the algorithm\n",
    "\n",
    "#print(graph)\n",
    "graph = nx.to_dict_of_lists(ngraph)\n",
    "'''\n",
    "if graph_check(graph):\n",
    "    print(\"Graph is properly structured\")\n",
    "    #input(\"correct\")\n",
    "    removed_vertices = get_influencers(graph, ngraph, 3)\n",
    "else:\n",
    "    print(\"Graph not properly structured\")\n",
    "    #input(\"npot correct\")\n",
    "'''\n",
    "removed_vertices = get_influencers(graph, ngraph, 3)\n",
    "print(removed_vertices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08b691cf8a3a31d1bdec91e16636791722048a283f28ba8b35477374ad55e1c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
